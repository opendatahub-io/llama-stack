{
  "test_id": "tests/integration/responses/test_tool_responses.py::test_response_sequential_file_search[client_with_models-txt=openai/gpt-4o:emb=openai/text-embedding-3-small:dim=1536]",
  "request": {
    "method": "POST",
    "url": "https://api.openai.com/v1/v1/chat/completions",
    "headers": {},
    "body": {
      "model": "gpt-4o",
      "messages": [
        {
          "role": "user",
          "content": "How many experts does the Llama 4 Maverick model have?"
        },
        {
          "role": "assistant",
          "content": "",
          "tool_calls": [
            {
              "index": 0,
              "id": "call_zS2WxgXWetjnlPt2MzH9Asrc",
              "type": "function",
              "function": {
                "name": "knowledge_search",
                "arguments": "{\"query\":\"Llama 4 Maverick model number of experts\"}"
              }
            }
          ]
        },
        {
          "role": "tool",
          "tool_call_id": "call_zS2WxgXWetjnlPt2MzH9Asrc",
          "content": [
            {
              "type": "text",
              "text": "knowledge_search tool found 1 chunks:\nBEGIN of knowledge_search tool results.\n"
            },
            {
              "type": "text",
              "text": "[1] document_id: file-5217982280, score: 2.57802841833685, attributes: {'filename': 'test_sequential_file_search.txt', 'document_id': 'file-5217982280', 'token_count': 19.0, 'metadata_token_count': 11.0} (cite as <|file-5217982280|>)\nThe Llama 4 Maverick model has 128 experts in its mixture of experts architecture.\n"
            },
            {
              "type": "text",
              "text": "END of knowledge_search tool results.\n"
            },
            {
              "type": "text",
              "text": "The above results were retrieved to help answer the user's query: \"Llama 4 Maverick model number of experts\". Use them as supporting information only in answering this query. Cite sources immediately at the end of sentences before punctuation, using `<|file-id|>` format (e.g., 'This is a fact <|file-Cn3MSNn72ENTiiq11Qda4A|>.'). Do not add extra punctuation. Use only the file IDs provided (do not invent new ones).\n"
            }
          ]
        },
        {
          "role": "assistant",
          "content": "The Llama 4 Maverick model has 128 experts in its mixture of experts architecture <|file-5217982280|>."
        },
        {
          "role": "user",
          "content": "Can you tell me more about the architecture?"
        },
        {
          "role": "assistant",
          "content": "",
          "tool_calls": [
            {
              "index": 0,
              "id": "call_eC40X8CzoIfT4BUnCbmNGlbT",
              "type": "function",
              "function": {
                "name": "knowledge_search",
                "arguments": "{\"query\":\"Llama 4 Maverick model architecture\"}"
              }
            }
          ]
        },
        {
          "role": "tool",
          "tool_call_id": "call_eC40X8CzoIfT4BUnCbmNGlbT",
          "content": [
            {
              "type": "text",
              "text": "knowledge_search tool found 1 chunks:\nBEGIN of knowledge_search tool results.\n"
            },
            {
              "type": "text",
              "text": "[1] document_id: file-5217982280, score: 1.9325686555844606, attributes: {'filename': 'test_sequential_file_search.txt', 'document_id': 'file-5217982280', 'token_count': 19.0, 'metadata_token_count': 11.0} (cite as <|file-5217982280|>)\nThe Llama 4 Maverick model has 128 experts in its mixture of experts architecture.\n"
            },
            {
              "type": "text",
              "text": "END of knowledge_search tool results.\n"
            },
            {
              "type": "text",
              "text": "The above results were retrieved to help answer the user's query: \"Llama 4 Maverick model architecture\". Use them as supporting information only in answering this query. Cite sources immediately at the end of sentences before punctuation, using `<|file-id|>` format (e.g., 'This is a fact <|file-Cn3MSNn72ENTiiq11Qda4A|>.'). Do not add extra punctuation. Use only the file IDs provided (do not invent new ones).\n"
            }
          ]
        }
      ],
      "stream": true,
      "tools": [
        {
          "type": "function",
          "function": {
            "name": "knowledge_search",
            "description": "Search for information in a database.",
            "parameters": {
              "type": "object",
              "properties": {
                "query": {
                  "type": "string",
                  "description": "The query to search for. Can be a natural language sentence or keywords."
                }
              },
              "required": [
                "query"
              ]
            }
          }
        }
      ]
    },
    "endpoint": "/v1/chat/completions",
    "model": "gpt-4o"
  },
  "response": {
    "body": [
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-b6484b82fd6d",
          "choices": [
            {
              "delta": {
                "content": "",
                "function_call": null,
                "refusal": null,
                "role": "assistant",
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_f64f290af2",
          "usage": null,
          "obfuscation": "YG2gnXGln3w"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-b6484b82fd6d",
          "choices": [
            {
              "delta": {
                "content": "The available information only mentions that the Llama ",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_f64f290af2",
          "usage": null,
          "obfuscation": "zsQxdAF7Bf"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-b6484b82fd6d",
          "choices": [
            {
              "delta": {
                "content": "4 Maverick model has a mixture of experts architecture with ",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_f64f290af2",
          "usage": null,
          "obfuscation": "RS3quzkVDo6p"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-b6484b82fd6d",
          "choices": [
            {
              "delta": {
                "content": "128 experts <|file-5217982280|>.",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_f64f290af2",
          "usage": null,
          "obfuscation": "AA2MyYWwqU"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-b6484b82fd6d",
          "choices": [
            {
              "delta": {
                "content": " Further details about its architecture were not provided in the current data.",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_f64f290af2",
          "usage": null,
          "obfuscation": "PKOKN"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-b6484b82fd6d",
          "choices": [
            {
              "delta": {
                "content": null,
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": "stop",
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_f64f290af2",
          "usage": null,
          "obfuscation": "bZqZWmb"
        }
      }
    ],
    "is_streaming": true
  },
  "id_normalization_mapping": {}
}
