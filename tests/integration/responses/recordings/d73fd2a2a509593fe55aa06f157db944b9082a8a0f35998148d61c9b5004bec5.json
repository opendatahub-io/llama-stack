{
  "test_id": "tests/integration/responses/test_tool_responses.py::test_response_non_streaming_web_search[openai_client-txt=openai/gpt-4o-llama_experts]",
  "request": {
    "method": "POST",
    "url": "https://api.openai.com/v1/v1/chat/completions",
    "headers": {},
    "body": {
      "model": "gpt-4o",
      "messages": [
        {
          "role": "user",
          "content": "How many experts does the Llama 4 Maverick model have?"
        },
        {
          "role": "assistant",
          "content": "",
          "tool_calls": [
            {
              "index": 0,
              "id": "call_fY5J03lFbmThl4W9MutX0D1g",
              "type": "function",
              "function": {
                "name": "web_search",
                "arguments": "{\"query\":\"Llama 4 Maverick model experts\"}"
              }
            }
          ]
        },
        {
          "role": "tool",
          "tool_call_id": "call_fY5J03lFbmThl4W9MutX0D1g",
          "content": "{\"query\": \"Llama 4 Maverick model experts\", \"top_k\": [{\"url\": \"https://console.groq.com/docs/model/meta-llama/llama-4-maverick-17b-128e-instruct\", \"title\": \"Llama 4 Maverick 17B 128E\", \"content\": \"Llama 4 Maverick is Meta's natively multimodal model that enables text and image understanding. With a 17 billion parameter mixture-of-experts architecture (128 experts), this model offers industry-leading performance for multimodal tasks like natural assistant-like chat, image recognition, and coding tasks. Llama 4 Maverick features an auto-regressive language model that uses a mixture-of-experts (MoE) architecture with 17B activated parameters (400B total) and incorporates early fusion for native multimodality. The model uses 128 experts to efficiently handle both text and image inputs while maintaining high performance across chat, knowledge, and code generation tasks, with a knowledge cutoff of August 2024. * For multimodal applications, this model supports up to 5 image inputs create(  model =\\\"meta-llama/llama-4-maverick-17b-128e-instruct\\\",   messages =[  {  \\\"role\\\":  \\\"user\\\",   \\\"content\\\":  \\\"Explain why fast inference is critical for reasoning models\\\"   }   ]  )  print(completion.\", \"score\": 0.9170729, \"raw_content\": null}, {\"url\": \"https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E\", \"title\": \"meta-llama/Llama-4-Maverick-17B-128E - Hugging Face\", \"content\": \"Model Architecture: The Llama 4 models are auto-regressive language models that use a mixture-of-experts (MoE) architecture and incorporate\", \"score\": 0.8021998, \"raw_content\": null}, {\"url\": \"https://www.ibm.com/new/announcements/meta-llama-4-maverick-and-llama-4-scout-now-available-in-watsonx-ai\", \"title\": \"Meta Llama 4 Maverick and Llama 4 Scout now available in watsonx ...\", \"content\": \"# Meta Llama 4 Maverick and Llama 4 Scout now available in watsonx.ai **IBM is excited to announce the addition of Meta\\u2019s latest generation of open models, Llama 4, to** **watsonx.ai****.** Llama 4 Scout and Llama 4 Maverick, the first mixture of experts (MoE) models released by Meta, provide frontier multimodal performance, high speeds, low cost, and industry leading context length. With the introduction of these latest offerings from Meta, IBM now supports a total of 13 Meta models in the expansive library of \\u00a0foundation models available in watsonx.ai. Trained on 40 trillion tokens of data, Llama 4 Scout offers performance rivalling or exceeding that of models with significantly larger active parameter counts while keeping costs and latency low. ## Llama 4 models on IBM watsonx\", \"score\": 0.78194773, \"raw_content\": null}, {\"url\": \"https://medium.com/@divyanshbhatiajm19/metas-llama-4-family-the-complete-guide-to-scout-maverick-and-behemoth-ai-models-in-2025-21a90c882e8a\", \"title\": \"Meta's Llama 4 Family: The Complete Guide to Scout, Maverick, and ...\", \"content\": \"# Meta\\u2019s Llama 4 Family: The Complete Guide to Scout, Maverick, and Behemoth AI Models in 2025 Feature Llama 4 Scout Llama 4 Maverick Llama 4 Behemoth **Total Parameters** 109B 400B ~2T **Active Parameters** 17B 17B 288B **Expert Count** 16 128 16 **Context Window** 10M tokens 1M tokens Not specified **Hardware Requirements** Single H100 GPU Single H100 DGX host Multiple GPUs **Inference Cost** Not specified $0.19-$0.49 per 1M tokens Not specified **Release Status** Available now Available now In training **Primary Use Cases** Long-context analysis, code processing High-performance multimodal applications Research, STEM reasoning The Llama 4 family represents Meta\\u2019s most significant AI development to date, with each model offering distinct advantages for different use cases:\", \"score\": 0.69672287, \"raw_content\": null}, {\"url\": \"https://www.llama.com/models/llama-4/\", \"title\": \"Unmatched Performance and Efficiency | Llama 4\", \"content\": \"# Llama 4 # Llama 4 Llama 4 Scout Class-leading natively multimodal model that offers superior text and visual intelligence, single H100 GPU efficiency, and a 10M context window for seamless long document analysis. Llama 4 MaverickIndustry-leading natively multimodal model for image and text understanding with groundbreaking intelligence and fast responses at a low cost. We evaluated model performance on a suite of common benchmarks across a wide range of languages, testing for coding, reasoning, knowledge, vision understanding, multilinguality, and long context. 4. Specialized long context evals are not traditionally reported for generalist models, so we share internal runs to showcase llama's frontier performance. 4. Specialized long context evals are not traditionally reported for generalist models, so we share internal runs to showcase llama's frontier performance.\", \"score\": 0.629889, \"raw_content\": null}]}"
        }
      ],
      "stream": true,
      "tools": [
        {
          "type": "function",
          "function": {
            "name": "web_search",
            "description": "Search the web for information",
            "parameters": {
              "type": "object",
              "properties": {
                "query": {
                  "type": "string",
                  "description": "The query to search for"
                }
              },
              "required": [
                "query"
              ]
            }
          }
        }
      ]
    },
    "endpoint": "/v1/chat/completions",
    "model": "gpt-4o"
  },
  "response": {
    "body": [
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": "",
                "function_call": null,
                "refusal": null,
                "role": "assistant",
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "KqiTQCjhMbm"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": "The",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "3AWFgxDkif"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": " L",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "z4jSdqjuAjz"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": "lama",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "6SJ62cG4N"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": " ",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "DeVoi87Ep9bZ"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": "4",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "Jzb6nfJOvUEe"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": " Maver",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "pea55AJ"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": "ick",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "o93CMh6Uor"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": " model",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "I14Egiu"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": " consists",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "Xy7N"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": " of",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "0doaPIA0B9"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": " ",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "QYxLpUjWCObi"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": "128",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "g9vxaB5e8T"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": " experts",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "JMAgP"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": ".",
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": null,
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "OpxtPMu3IlEc"
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-d73fd2a2a509",
          "choices": [
            {
              "delta": {
                "content": null,
                "function_call": null,
                "refusal": null,
                "role": null,
                "tool_calls": null
              },
              "finish_reason": "stop",
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "gpt-4o-2024-08-06",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": "fp_1827dd0c55",
          "usage": null,
          "obfuscation": "Qca9DU4"
        }
      }
    ],
    "is_streaming": true
  }
}
